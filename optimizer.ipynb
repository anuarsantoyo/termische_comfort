{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Optimizer\n",
    "Gets data and uses it to optimize a method (imported from method.py) using a loss function and tests it against unseen data.\n",
    "TODO:\n",
    "- Cross Validation implementation\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.optim as optim"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    1. Geschlecht:  2. Alter:  3. Körpergröße (in cm)  \\\n0                0         62                     162   \n1                0         36                     163   \n2                0         23                     168   \n3                0         22                     178   \n4                0         25                     163   \n5                0         27                     168   \n6                1         38                     187   \n7                1         73                     167   \n8                1         61                     176   \n9                1         47                     184   \n10               0         35                     176   \n11               0         55                     170   \n12               0         83                     157   \n13               0         86                     164   \n14               0         83                     169   \n15               0         49                     160   \n16               1         52                     186   \n17               0         60                     178   \n18               0         23                     168   \n19               1         45                     175   \n20               1         25                     198   \n21               0         63                     172   \n22               1         27                     183   \n23               0         14                     153   \n24               0         53                     173   \n25               0         18                     158   \n26               0         41                     177   \n27               0         70                     150   \n28               1         20                     186   \n29               1         23                     168   \n30               1         24                     190   \n31               0         23                     168   \n32               0         31                     168   \n33               1         70                     173   \n34               1         19                     170   \n35               1         25                     162   \n36               0         40                     156   \n\n    4. Körpergewicht (in kg)  8. Wie lange fahren Sie schon auf dem Bus?  \\\n0                         60                                           0   \n1                         65                                           0   \n2                         68                                           1   \n3                         80                                           0   \n4                         65                                           0   \n5                         57                                           2   \n6                         69                                           0   \n7                         83                                           0   \n8                         80                                           0   \n9                         81                                           1   \n10                        67                                           0   \n11                        74                                           0   \n12                        53                                           1   \n13                        61                                           1   \n14                        70                                           1   \n15                        50                                           1   \n16                        95                                           1   \n17                        84                                           0   \n18                        72                                           1   \n19                       130                                           1   \n20                        98                                           0   \n21                        63                                           0   \n22                       110                                           0   \n23                        50                                           0   \n24                        69                                           0   \n25                        60                                           0   \n26                        60                                           1   \n27                        45                                           1   \n28                        75                                           1   \n29                        72                                           1   \n30                        79                                           0   \n31                        75                                           0   \n32                        60                                           1   \n33                        85                                           0   \n34                        70                                           0   \n35                        70                                           1   \n36                        73                                           1   \n\n    10. Bitte geben Sie an ob Sie sitzen oder stehen:  \\\n0                                                   0   \n1                                                   0   \n2                                                   0   \n3                                                   0   \n4                                                   0   \n5                                                   0   \n6                                                   0   \n7                                                   0   \n8                                                   0   \n9                                                   1   \n10                                                  0   \n11                                                  0   \n12                                                  0   \n13                                                  0   \n14                                                  0   \n15                                                  0   \n16                                                  0   \n17                                                  0   \n18                                                  0   \n19                                                  0   \n20                                                  0   \n21                                                  0   \n22                                                  0   \n23                                                  0   \n24                                                  0   \n25                                                  0   \n26                                                  0   \n27                                                  0   \n28                                                  0   \n29                                                  0   \n30                                                  0   \n31                                                  0   \n32                                                  0   \n33                                                  0   \n34                                                  0   \n35                                                  0   \n36                                                  1   \n\n    11. Bitte geben Sie Ihre Position im Bus an:  \\\n0                                            0.0   \n1                                            1.0   \n2                                            2.0   \n3                                            3.0   \n4                                            4.0   \n5                                            4.0   \n6                                            5.0   \n7                                            5.0   \n8                                            4.0   \n9                                            5.0   \n10                                           1.0   \n11                                           1.0   \n12                                           4.0   \n13                                           4.0   \n14                                           4.0   \n15                                           3.0   \n16                                           3.0   \n17                                           3.0   \n18                                           0.0   \n19                                           3.0   \n20                                           4.0   \n21                                           2.0   \n22                                           3.0   \n23                                           1.0   \n24                                           4.0   \n25                                           3.0   \n26                                           4.0   \n27                                           6.0   \n28                                           1.0   \n29                                           2.0   \n30                                           5.0   \n31                                           2.0   \n32                                           5.0   \n33                                           3.0   \n34                                           4.0   \n35                                           3.0   \n36                                           4.0   \n\n    12. Bitte geben Sie an, ob sie näher einer Fenster oder dem Gang sind:  \\\n0                                                   0                        \n1                                                   0                        \n2                                                   0                        \n3                                                   1                        \n4                                                   1                        \n5                                                   1                        \n6                                                   0                        \n7                                                   1                        \n8                                                   0                        \n9                                                   0                        \n10                                                  0                        \n11                                                  0                        \n12                                                  1                        \n13                                                  0                        \n14                                                  0                        \n15                                                  0                        \n16                                                  1                        \n17                                                  1                        \n18                                                  1                        \n19                                                  0                        \n20                                                  1                        \n21                                                  1                        \n22                                                  0                        \n23                                                  1                        \n24                                                  0                        \n25                                                  1                        \n26                                                  1                        \n27                                                  1                        \n28                                                  1                        \n29                                                  0                        \n30                                                  1                        \n31                                                  0                        \n32                                                  1                        \n33                                                  1                        \n34                                                  0                        \n35                                                  1                        \n36                                                  1                        \n\n    clothing_insulation   comfort  \n0                    31  1.000000  \n1                    21  1.666667  \n2                    35  1.000000  \n3                    26  1.333333  \n4                    26  1.333333  \n5                    26  1.666667  \n6                    22  1.666667  \n7                    32  2.000000  \n8                    29  1.333333  \n9                    22  1.333333  \n10                   30  1.666667  \n11                   24  2.000000  \n12                   29  0.333333  \n13                   31  0.666667  \n14                   31  0.000000  \n15                   29  1.666667  \n16                   25  2.000000  \n17                   28  1.666667  \n18                   28  1.666667  \n19                   22  2.333333  \n20                   24  2.333333  \n21                   29  2.000000  \n22                   20  1.666667  \n23                   31  2.000000  \n24                   33  0.666667  \n25                   26  1.666667  \n26                   33  1.000000  \n27                   24  1.333333  \n28                   31  2.666667  \n29                   28  1.333333  \n30                   26  2.000000  \n31                   28  1.666667  \n32                   30  2.666667  \n33                   26  2.333333  \n34                   26  1.000000  \n35                   29  2.000000  \n36                   29  1.333333  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1. Geschlecht:</th>\n      <th>2. Alter:</th>\n      <th>3. Körpergröße (in cm)</th>\n      <th>4. Körpergewicht (in kg)</th>\n      <th>8. Wie lange fahren Sie schon auf dem Bus?</th>\n      <th>10. Bitte geben Sie an ob Sie sitzen oder stehen:</th>\n      <th>11. Bitte geben Sie Ihre Position im Bus an:</th>\n      <th>12. Bitte geben Sie an, ob sie näher einer Fenster oder dem Gang sind:</th>\n      <th>clothing_insulation</th>\n      <th>comfort</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>62</td>\n      <td>162</td>\n      <td>60</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>31</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>36</td>\n      <td>163</td>\n      <td>65</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>21</td>\n      <td>1.666667</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>23</td>\n      <td>168</td>\n      <td>68</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>35</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>22</td>\n      <td>178</td>\n      <td>80</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>26</td>\n      <td>1.333333</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>25</td>\n      <td>163</td>\n      <td>65</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>26</td>\n      <td>1.333333</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>27</td>\n      <td>168</td>\n      <td>57</td>\n      <td>2</td>\n      <td>0</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>26</td>\n      <td>1.666667</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>38</td>\n      <td>187</td>\n      <td>69</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5.0</td>\n      <td>0</td>\n      <td>22</td>\n      <td>1.666667</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1</td>\n      <td>73</td>\n      <td>167</td>\n      <td>83</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5.0</td>\n      <td>1</td>\n      <td>32</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>61</td>\n      <td>176</td>\n      <td>80</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4.0</td>\n      <td>0</td>\n      <td>29</td>\n      <td>1.333333</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1</td>\n      <td>47</td>\n      <td>184</td>\n      <td>81</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5.0</td>\n      <td>0</td>\n      <td>22</td>\n      <td>1.333333</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0</td>\n      <td>35</td>\n      <td>176</td>\n      <td>67</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>30</td>\n      <td>1.666667</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0</td>\n      <td>55</td>\n      <td>170</td>\n      <td>74</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>24</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0</td>\n      <td>83</td>\n      <td>157</td>\n      <td>53</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>29</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0</td>\n      <td>86</td>\n      <td>164</td>\n      <td>61</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4.0</td>\n      <td>0</td>\n      <td>31</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0</td>\n      <td>83</td>\n      <td>169</td>\n      <td>70</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4.0</td>\n      <td>0</td>\n      <td>31</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0</td>\n      <td>49</td>\n      <td>160</td>\n      <td>50</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>29</td>\n      <td>1.666667</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>1</td>\n      <td>52</td>\n      <td>186</td>\n      <td>95</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>25</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0</td>\n      <td>60</td>\n      <td>178</td>\n      <td>84</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>28</td>\n      <td>1.666667</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0</td>\n      <td>23</td>\n      <td>168</td>\n      <td>72</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>28</td>\n      <td>1.666667</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>1</td>\n      <td>45</td>\n      <td>175</td>\n      <td>130</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>22</td>\n      <td>2.333333</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>1</td>\n      <td>25</td>\n      <td>198</td>\n      <td>98</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>24</td>\n      <td>2.333333</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0</td>\n      <td>63</td>\n      <td>172</td>\n      <td>63</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>29</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>1</td>\n      <td>27</td>\n      <td>183</td>\n      <td>110</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>20</td>\n      <td>1.666667</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0</td>\n      <td>14</td>\n      <td>153</td>\n      <td>50</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>31</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0</td>\n      <td>53</td>\n      <td>173</td>\n      <td>69</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4.0</td>\n      <td>0</td>\n      <td>33</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0</td>\n      <td>18</td>\n      <td>158</td>\n      <td>60</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>26</td>\n      <td>1.666667</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0</td>\n      <td>41</td>\n      <td>177</td>\n      <td>60</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>33</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>0</td>\n      <td>70</td>\n      <td>150</td>\n      <td>45</td>\n      <td>1</td>\n      <td>0</td>\n      <td>6.0</td>\n      <td>1</td>\n      <td>24</td>\n      <td>1.333333</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>1</td>\n      <td>20</td>\n      <td>186</td>\n      <td>75</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>31</td>\n      <td>2.666667</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>1</td>\n      <td>23</td>\n      <td>168</td>\n      <td>72</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>28</td>\n      <td>1.333333</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>1</td>\n      <td>24</td>\n      <td>190</td>\n      <td>79</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5.0</td>\n      <td>1</td>\n      <td>26</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>0</td>\n      <td>23</td>\n      <td>168</td>\n      <td>75</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>28</td>\n      <td>1.666667</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>0</td>\n      <td>31</td>\n      <td>168</td>\n      <td>60</td>\n      <td>1</td>\n      <td>0</td>\n      <td>5.0</td>\n      <td>1</td>\n      <td>30</td>\n      <td>2.666667</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>1</td>\n      <td>70</td>\n      <td>173</td>\n      <td>85</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>26</td>\n      <td>2.333333</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>1</td>\n      <td>19</td>\n      <td>170</td>\n      <td>70</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4.0</td>\n      <td>0</td>\n      <td>26</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>1</td>\n      <td>25</td>\n      <td>162</td>\n      <td>70</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>29</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>0</td>\n      <td>40</td>\n      <td>156</td>\n      <td>73</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>29</td>\n      <td>1.333333</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Load the data\n",
    "data_path = 'data/survey_2022-06-08.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Scale Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(df)\n",
    "y = X[:,-1]\n",
    "x = X[:,:-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cross Validation Split #TODO"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train Test Split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "dtype = torch.float\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train = torch.tensor(x_train,dtype=dtype)\n",
    "x_test = torch.tensor(x_test, dtype=dtype)\n",
    "y_test = torch.tensor(y_test, dtype=dtype).reshape(-1,1)\n",
    "y_train = torch.tensor(y_train, dtype=dtype).reshape(-1,1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train loss: 0.06557678431272507, test loss: 0.023561634123325348\n",
      "Epoch: 100, train loss: 0.0054340544156730175, test loss: 0.06071560084819794\n",
      "Epoch: 200, train loss: 0.00015590785187669098, test loss: 0.08227647840976715\n",
      "Epoch: 300, train loss: 5.491127012646757e-05, test loss: 0.07766091823577881\n",
      "Epoch: 400, train loss: 5.0028549594571814e-05, test loss: 0.07658641040325165\n",
      "Epoch: 500, train loss: 2.8776545150321908e-05, test loss: 0.07628928869962692\n",
      "Epoch: 600, train loss: 2.5777324481168762e-05, test loss: 0.07640906423330307\n",
      "Epoch: 700, train loss: 2.0653400497394614e-05, test loss: 0.07647870481014252\n",
      "Epoch: 800, train loss: 1.2701708328677341e-05, test loss: 0.07665390521287918\n",
      "Epoch: 900, train loss: 7.998724868230056e-06, test loss: 0.07675064355134964\n",
      "Epoch: 1000, train loss: 5.5523505579913035e-06, test loss: 0.07675622403621674\n",
      "Epoch: 1100, train loss: 3.926902536477428e-06, test loss: 0.07679638266563416\n",
      "Epoch: 1200, train loss: 2.9076395549054723e-06, test loss: 0.07680270820856094\n",
      "Epoch: 1300, train loss: 2.1278140138747403e-06, test loss: 0.07679672539234161\n",
      "Epoch: 1400, train loss: 1.5814503058209084e-06, test loss: 0.07679805159568787\n",
      "Epoch: 1500, train loss: 1.1984880075033288e-06, test loss: 0.07680624723434448\n",
      "Epoch: 1600, train loss: 8.956147894423339e-07, test loss: 0.07681972533464432\n",
      "Epoch: 1700, train loss: 7.152193575166166e-07, test loss: 0.07692976295948029\n",
      "Epoch: 1800, train loss: 5.839251571160275e-07, test loss: 0.07701495289802551\n",
      "Epoch: 1900, train loss: 4.958051817993692e-07, test loss: 0.07709050178527832\n",
      "Epoch: 2000, train loss: 4.174721368599421e-07, test loss: 0.07713407278060913\n",
      "Epoch: 2100, train loss: 3.598837849949632e-07, test loss: 0.07718525826931\n",
      "Epoch: 2200, train loss: 3.085114883560891e-07, test loss: 0.07720664888620377\n",
      "Epoch: 2300, train loss: 2.6798872454492084e-07, test loss: 0.07724308967590332\n",
      "Epoch: 2400, train loss: 2.3379517699595453e-07, test loss: 0.07726901769638062\n",
      "Epoch: 2500, train loss: 2.0556221613787784e-07, test loss: 0.07728712260723114\n",
      "Epoch: 2600, train loss: 1.8135253299078613e-07, test loss: 0.07731117308139801\n",
      "Epoch: 2700, train loss: 1.6128814195326413e-07, test loss: 0.07732754945755005\n",
      "Epoch: 2800, train loss: 1.4377454249370203e-07, test loss: 0.07734365016222\n",
      "Epoch: 2900, train loss: 1.2890794209852174e-07, test loss: 0.07736210525035858\n",
      "Epoch: 3000, train loss: 1.1642985953130847e-07, test loss: 0.07737457752227783\n",
      "Epoch: 3100, train loss: 1.0534114380789106e-07, test loss: 0.07738763093948364\n",
      "Epoch: 3200, train loss: 9.591364857897133e-08, test loss: 0.07739664614200592\n",
      "Epoch: 3300, train loss: 8.776007121014118e-08, test loss: 0.07741370797157288\n",
      "Epoch: 3400, train loss: 8.042240295935699e-08, test loss: 0.07742016017436981\n",
      "Epoch: 3500, train loss: 7.413655822574583e-08, test loss: 0.07742762565612793\n",
      "Epoch: 3600, train loss: 6.852146583469221e-08, test loss: 0.07743538916110992\n",
      "Epoch: 3700, train loss: 6.36535304465724e-08, test loss: 0.07744240760803223\n",
      "Epoch: 3800, train loss: 5.934724356393417e-08, test loss: 0.07745186984539032\n",
      "Epoch: 3900, train loss: 5.5407046062327936e-08, test loss: 0.07745630294084549\n",
      "Epoch: 4000, train loss: 5.2063729327755937e-08, test loss: 0.07746383547782898\n",
      "Epoch: 4100, train loss: 4.89463900521514e-08, test loss: 0.07746796309947968\n",
      "Epoch: 4200, train loss: 4.614571125216571e-08, test loss: 0.07747197151184082\n",
      "Epoch: 4300, train loss: 4.36523031055458e-08, test loss: 0.07747572660446167\n",
      "Epoch: 4400, train loss: 4.1407158590800464e-08, test loss: 0.07747941464185715\n",
      "Epoch: 4500, train loss: 3.937283210575515e-08, test loss: 0.07748192548751831\n",
      "Epoch: 4600, train loss: 3.7530231367099987e-08, test loss: 0.0774848535656929\n",
      "Epoch: 4700, train loss: 3.585731889188537e-08, test loss: 0.07748730480670929\n",
      "Epoch: 4800, train loss: 3.437915552240156e-08, test loss: 0.07749086618423462\n",
      "Epoch: 4900, train loss: 3.2973225927435124e-08, test loss: 0.07749263942241669\n",
      "Epoch: 5000, train loss: 3.170103823890713e-08, test loss: 0.07749418169260025\n",
      "Epoch: 5100, train loss: 3.053257202623172e-08, test loss: 0.07749547064304352\n",
      "Epoch: 5200, train loss: 2.9461933337415758e-08, test loss: 0.07749661058187485\n",
      "Epoch: 5300, train loss: 2.8481625946596978e-08, test loss: 0.07749815285205841\n",
      "Epoch: 5400, train loss: 2.757935924080357e-08, test loss: 0.07749957591295242\n",
      "Epoch: 5500, train loss: 2.6771292738203556e-08, test loss: 0.07750190794467926\n",
      "Epoch: 5600, train loss: 2.598050130586671e-08, test loss: 0.07750283181667328\n",
      "Epoch: 5700, train loss: 2.5287187455091953e-08, test loss: 0.0775039792060852\n",
      "Epoch: 5800, train loss: 2.4622318406386512e-08, test loss: 0.07750488072633743\n",
      "Epoch: 5900, train loss: 2.400391885259978e-08, test loss: 0.07750584185123444\n",
      "Epoch: 6000, train loss: 2.3443563534897294e-08, test loss: 0.07750675827264786\n",
      "Epoch: 6100, train loss: 2.291328726755637e-08, test loss: 0.07750806957483292\n",
      "Epoch: 6200, train loss: 2.2416426048721405e-08, test loss: 0.07750822603702545\n",
      "Epoch: 6300, train loss: 2.1959987606123832e-08, test loss: 0.07750952988862991\n",
      "Epoch: 6400, train loss: 2.153182698805267e-08, test loss: 0.07750978320837021\n",
      "Epoch: 6500, train loss: 2.1142668060747383e-08, test loss: 0.07751117646694183\n",
      "Epoch: 6600, train loss: 2.0760177577017203e-08, test loss: 0.07751090824604034\n",
      "Epoch: 6700, train loss: 2.0421655477775857e-08, test loss: 0.07751181721687317\n",
      "Epoch: 6800, train loss: 2.0094496733236156e-08, test loss: 0.07751220464706421\n",
      "Epoch: 6900, train loss: 1.9794944350337573e-08, test loss: 0.07751268148422241\n",
      "Epoch: 7000, train loss: 1.9510933313426904e-08, test loss: 0.07751356065273285\n",
      "Epoch: 7100, train loss: 1.9244692950337594e-08, test loss: 0.07751373201608658\n",
      "Epoch: 7200, train loss: 1.899617529943498e-08, test loss: 0.07751408964395523\n",
      "Epoch: 7300, train loss: 1.87606481460989e-08, test loss: 0.07751449942588806\n",
      "Epoch: 7400, train loss: 1.854858133754078e-08, test loss: 0.07751543819904327\n",
      "Epoch: 7500, train loss: 1.8341781427011483e-08, test loss: 0.07751541584730148\n",
      "Epoch: 7600, train loss: 1.815327443921433e-08, test loss: 0.07751575112342834\n",
      "Epoch: 7700, train loss: 1.797588922158866e-08, test loss: 0.07751623541116714\n",
      "Epoch: 7800, train loss: 1.7807481711429318e-08, test loss: 0.07751666009426117\n",
      "Epoch: 7900, train loss: 1.7644536498551133e-08, test loss: 0.0775168389081955\n",
      "Epoch: 8000, train loss: 1.7494921067395808e-08, test loss: 0.07751700282096863\n",
      "Epoch: 8100, train loss: 1.7358859238925106e-08, test loss: 0.07751727849245071\n",
      "Epoch: 8200, train loss: 1.723066311853927e-08, test loss: 0.0775175541639328\n",
      "Epoch: 8300, train loss: 1.7106252414578194e-08, test loss: 0.07751748710870743\n",
      "Epoch: 8400, train loss: 1.6996652973944038e-08, test loss: 0.07751765102148056\n",
      "Epoch: 8500, train loss: 1.6894011523049812e-08, test loss: 0.07751787453889847\n",
      "Epoch: 8600, train loss: 1.6795969060012794e-08, test loss: 0.07751772552728653\n",
      "Epoch: 8700, train loss: 1.670221472238609e-08, test loss: 0.07751788944005966\n",
      "Epoch: 8800, train loss: 1.6625062215780417e-08, test loss: 0.07751787453889847\n",
      "Epoch: 8900, train loss: 1.6543806324875732e-08, test loss: 0.0775178000330925\n",
      "Epoch: 9000, train loss: 1.6470400154844356e-08, test loss: 0.07751783728599548\n",
      "Epoch: 9100, train loss: 1.640280089532098e-08, test loss: 0.0775178000330925\n",
      "Epoch: 9200, train loss: 1.6333393304535093e-08, test loss: 0.0775177925825119\n",
      "Epoch: 9300, train loss: 1.6279772196980957e-08, test loss: 0.07751785218715668\n",
      "Epoch: 9400, train loss: 1.6221081367007173e-08, test loss: 0.07751783728599548\n",
      "Epoch: 9500, train loss: 1.617695843947331e-08, test loss: 0.07751776278018951\n",
      "Epoch: 9600, train loss: 1.612637134940087e-08, test loss: 0.0775177925825119\n",
      "Epoch: 9700, train loss: 1.608022337507009e-08, test loss: 0.0775178000330925\n",
      "Epoch: 9800, train loss: 1.604000310351239e-08, test loss: 0.0775177925825119\n",
      "Epoch: 9900, train loss: 1.600285770564369e-08, test loss: 0.07751794159412384\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from methods import *\n",
    "from torch import nn\n",
    "\n",
    "epochs = 10000\n",
    "method = NN(input_size=x_train.shape[1])\n",
    "criterion = nn.MSELoss()\n",
    "params_to_be_optimized = method.get_parameters()\n",
    "optimizer = optim.Adam(params_to_be_optimized, lr=0.01)\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.999)\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  iteration_time = time.time()\n",
    "  optimizer.zero_grad()\n",
    "\n",
    "  # forward pass\n",
    "  y_train_predicted = method.predict(x_train)\n",
    "  loss = criterion(y_train_predicted, y_train)\n",
    "\n",
    "  # backward pass\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  scheduler.step()\n",
    "\n",
    "\n",
    "  with torch.no_grad():\n",
    "\n",
    "    y_train_predicted = method.predict(x_train)\n",
    "    train_loss = criterion(y_train_predicted, y_train)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    y_test_predicted = method.predict(x_test)\n",
    "    test_loss = criterion(y_test_predicted, y_test)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    if epoch%100==0:\n",
    "      print(f'Epoch: {epoch}, train loss: {train_loss}, test loss: {test_loss}')\n",
    "\n",
    "\n",
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(test_losses, label='test loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "outputs": [],
   "source": [
    "# Rescale test result to original values\n",
    "zeros = np.zeros(x_test.shape)\n",
    "test_predicted = np.concatenate((zeros, method.predict(x_test).detach().numpy()),axis=1)\n",
    "test_predicted= scaler.inverse_transform(test_predicted)[:,-1]\n",
    "\n",
    "test_target = np.concatenate((zeros, y_test.detach().numpy()),axis=1)\n",
    "test_target = scaler.inverse_transform(test_target)[:,-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "outputs": [],
   "source": [
    "# Calculate percentage error\n",
    "percentage_error = (test_target - test_predicted)/test_target"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot histogram of percentage error\n",
    "plt.hist(percentage_error)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}